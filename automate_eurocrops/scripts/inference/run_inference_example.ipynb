{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b86c8f46",
   "metadata": {},
   "source": [
    "# Sample Inference using RAG and DPL\n",
    "Here we use the precomputed context and translations from Deepl to create the prompt that will be passed into the Mistral Nemo 12B model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93781ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from pydantic import BaseModel, ValidationError, validator, Field\n",
    "\n",
    "\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78281e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up paths and model names\n",
    "model_id = \"mistralai/Mistral-Nemo-Instruct-2407\"\n",
    "context_file = '/home/automate_eurocrops/data/BW_context.pkl'\n",
    "data_root = '/home/automate_eurocrops/data/raw/'\n",
    "HCAT_fname = 'HCAT4.xlsx'\n",
    "country_fname = 'BW.csv'\n",
    "# deepl file\n",
    "d_path = '/home/automate_eurocrops/data/processed/' \n",
    "file_name = 'BW_trans.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adaac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up mistral model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbfe324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the crop list to reference to-HCAT and crop descriptions to be translated and mapped\n",
    "with open(context_file, 'rb') as f:\n",
    "    contexts = pickle.load(f)\n",
    "\n",
    "hcat_file = pd.read_excel(data_root+HCAT_fname)\n",
    "country_file = pd.read_csv(data_root+country_fname ) \n",
    "hcat_name = hcat_file['HCAT4_name']\n",
    "original_name = country_file['original_name']   \n",
    "HCAT_list = list(hcat_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516a6897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the translations of the crop descriptions by deepl\n",
    "dpl = pd.read_excel(d_path+file_name)\n",
    "dpl_trans = dpl['dpl_trans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fff7b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To prevent hallucinations of non HCAT names being mapped to\n",
    "# pydantic function to ensure outputed HCAT is actually from the list of HCAT_names\n",
    "\n",
    "class HCAT(BaseModel):\n",
    "    # id: int\n",
    "    # original code will be appended as key outside llm prompt\n",
    "    original_name: str \n",
    "    HCAT_name: str\n",
    "    translated_name: str\n",
    "\n",
    "    @validator('HCAT_name')\n",
    "    def validate_HCAT_mapping(cls, v):\n",
    "        if v not in HCAT_list:\n",
    "            raise ValueError({v},' is not a valid HCAT mapping.')\n",
    "        return v\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23858e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the inference function\n",
    "# here to change the prompt, adjust whether if context/dpl translation is required.\n",
    "def perform_inference(model, data, hcatn, context, dpl_trans):\n",
    "        \"\"\"\n",
    "\n",
    "# code adapted from https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407 function calling with transformers\n",
    "\n",
    "\n",
    "Inputs:\n",
    "  - model: the llm to be used (loaded via AutoModelForCausalLM.from_pretrained)\n",
    "  - data: original crop description from the country GSA\n",
    "  - hcatn: HCAT list of allowed HCAT names \n",
    "  - context: text string of context by RAG via cosine similarity from AGROVOC and Agriprod (precomputed in advance)\n",
    "  - dpl_trans: DeepL translation of the original crop description\n",
    "\n",
    "Output:\n",
    "  - JSON of validated objects: {original_name, translated_name, HCAT_name}\n",
    "\"\"\"\n",
    "      \n",
    "        max_retries = 5 \n",
    "        for attempt in range(max_retries):\n",
    "        \n",
    "\n",
    "\n",
    "            prompt = f\"\"\"\n",
    "            [INST]\n",
    "            You are an assistant that answers ONLY with the required json output to the user's question. No explanations.\n",
    "            Based on the following agricultural information: {context}\n",
    "            \n",
    "            Given a description below:\n",
    "            \n",
    "            {data}\n",
    "            \n",
    "\n",
    "            First translate every part of the description to English, while taking into consideration that deepl's translation is {dpl_trans} \n",
    "            This is \"translated_name\"\n",
    "\n",
    "\n",
    "            Next use the \"translated_name\" to match based on the closest semantic meaning to an entry from this list of HCAT_names:\n",
    "\n",
    "            {hcatn}\n",
    "            The \"HCAT_name\" should be as specific as possible, prioritize species level semantic matches to the HCAT_names from the \"translated_name\"\n",
    "            Consider the entire \"translated_name\" and look for the HCAT_name that is the closest match to the entire description. \n",
    "            ALso map to the more informative HCAT_name.\n",
    "            E.g for root chicory, chicory is more informative than root so map to chicory_chicories\n",
    "            Summer crops should be the spring equivalent in \"HCAT_name\", but keep the translated_name as the original English translation\n",
    "            If the exact \"translated_name\" is not in the HCAT_names, find the upper class of crops that includes the crop in HCAT_names and map to its other class.\n",
    "            For example for prickly pear, the upper crop class is fruit, \"HCAT_name\" is other_orchards_fruits.\n",
    "            If the \"translated_name\" is not a crop or argriculture product, for example rocks or landscape features, \"HCAT_name\" is not_known_and_other\n",
    "            If the \"translated_name\" is a mix of crops, find the upper class of crops that includes all the crops in HCAT_names and map to the upper class\n",
    "            For example if \"translated_name\" is mixed alfafa and clover, the common upper crop class is legumes, \"HCAT_name\" is legumes.\n",
    "            Or if \"translated_name\" is mixed cultures, the common upper crop class is arable crops, HCAT_name\" is arable_crops\n",
    "            Trees and flowers are also agriculture products in HCAT.\n",
    "            \n",
    "            \n",
    "                \n",
    "\n",
    "\n",
    "            Return only in json format defined below:\n",
    "            '''\n",
    "            \"original_name\": \"{data}\", \"translated_name\": \"english translation of {data}\",  \"HCAT_name\": \"closest semantic match of translated name in HCAT_names\"\n",
    "            ''' \n",
    "            Only use a \"HCAT_name\" from the provided HCAT_names.\n",
    "            No other detail.\n",
    "\n",
    "            **Example Json Output:**\n",
    "            \"original_name\": \"Erdbeeren\", \"translated_name\": \"strawberries\",  \"HCAT_name\": \"strawberries\"\n",
    "\n",
    "            [/INST]\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "            # Tokenize input\n",
    "            tokens = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "            # Generate output tokens\n",
    "            with torch.no_grad():\n",
    "                out_tokens = model.generate(**tokens, max_new_tokens=100, temperature=0.35, top_p=0.9, eos_token_id=tokenizer.eos_token_id, do_sample=True)\n",
    "            # Decode tokens to string\n",
    "\n",
    "            result = tokenizer.decode(out_tokens[0][tokens['input_ids'].shape[1]:], skip_special_tokens=True).strip()\n",
    "           \n",
    "    \n",
    "\n",
    "            try:\n",
    "    \n",
    "                \n",
    "                validated = HCAT.parse_raw(result)\n",
    "                \n",
    "                print(\"Validated Crop:\", validated)\n",
    "                \n",
    "         \n",
    "                break  # exit loop if successful\n",
    "            except (json.JSONDecodeError, ValidationError) as e:\n",
    "                print(\"Parse failed. Re-prompting...\\n\")\n",
    "                print(f\"JSON Decode Error: {e}\")\n",
    "    \n",
    "                validated = HCAT(original_name=data, HCAT_name=\"not_known_and_other\", translated_name=\"\")\n",
    "                \n",
    "   \n",
    "\n",
    "        return validated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64b20e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform inference on one crop description\n",
    "output = perform_inference(model, original_name[0], hcat_name.to_list(), contexts[0], dpl_trans[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ec91a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print generation\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
